{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatimaAfzaal/Multiple-Ensemble-models-Diabetes-Prediction-Project-/blob/main/MultipleEnsembleModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQhasmlRUq5s"
      },
      "source": [
        "# Diabetes Prediction Project Using Hybrid models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jY1KmmPYzkY"
      },
      "source": [
        "## 1. 下载及导入所需要的包"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76HUhjE96NRi",
        "outputId": "964e5432-1176-4762-bb9f-3ac60db89b7a"
      },
      "outputs": [],
      "source": [
        "# pip install catboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4aOCc4F_deIL",
        "outputId": "f10c5d65-626c-4c69-91f8-c92d39a3f301"
      },
      "outputs": [],
      "source": [
        "import pandas as pd                                                        #for data manipulation\n",
        "import numpy as np                                                         #for numerical operations\n",
        "from matplotlib import pyplot as plt                                       #for visualization\n",
        "import seaborn as sns                                                      #for visualization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier                        #for using Random forest Classifier algorithm\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from joblib import dump, load\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score                                 #for accouracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7ptr0O5pafN"
      },
      "source": [
        "## 2. 导入训练集和测试集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset features: (74048, 15)\n",
            "Testing dataset features: (18513, 15)\n",
            "Training dataset target: (74048,)\n",
            "Testing dataset target: (18513,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import training dataset / 导入训练集\n",
        "train_df = pd.read_csv(\"C:/Users/dell/Desktop/final_project/data/train_data.csv\")\n",
        "Y_train = train_df['diabetes']  # Target variable for training dataset / 训练集目标变量\n",
        "X_train = train_df.iloc[:, :-1]  # Select all rows and all columns except the last one / 选择所有行和除了最后一列以外的所有列\n",
        "\n",
        "# Import testing dataset / 导入测试集\n",
        "test_df = pd.read_csv(\"C:/Users/dell/Desktop/final_project/data/test_data.csv\")\n",
        "Y_test = test_df['diabetes']  # Target variable for testing dataset / 测试集目标变量\n",
        "X_test = test_df.iloc[:, :-1]  # Select all rows and all columns except the last one / 选择所有行和除了最后一列以外的所有列\n",
        "\n",
        "# Output the result / 输出结果\n",
        "print(\"Training dataset features:\", X_train.shape)  # 训练集特征\n",
        "print(\"Testing dataset features:\", X_test.shape)  # 测试集特征\n",
        "print(\"Training dataset target:\", Y_train.shape)  # 训练集目标\n",
        "print(\"Testing dataset target:\", Y_test.shape)  # 测试集目标\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standardized Training dataset features: (74048, 15)\n",
            "Standardized Testing dataset features: (18513, 15)\n",
            "\n",
            "Standardized Training Data (First 5 rows):\n",
            "        age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
            "0  0.679474     -0.289059      -0.205737 -1.922380     0.610237   \n",
            "1  0.501401     -0.289059      -0.205737  0.170888    -1.996087   \n",
            "2 -1.679986     -0.289059      -0.205737 -2.006818    -0.692925   \n",
            "3  1.302728     -0.289059      -0.205737  0.170888     0.610237   \n",
            "4  0.323329     -0.289059      -0.205737  2.205246     0.710480   \n",
            "\n",
            "   blood_glucose_level  diabetes  gender_Female  gender_Male  gender_Other  \\\n",
            "0             1.851414 -0.310625      -1.187544     1.187973     -0.013251   \n",
            "1             0.282064 -0.310625       0.842074    -0.841770     -0.013251   \n",
            "2            -1.429954 -0.310625       0.842074    -0.841770     -0.013251   \n",
            "3             1.851414 -0.310625      -1.187544     1.187973     -0.013251   \n",
            "4            -1.001949 -0.310625       0.842074    -0.841770     -0.013251   \n",
            "\n",
            "   smoking_history_No Info  smoking_history_current  smoking_history_ever  \\\n",
            "0                -0.723379                -0.323878             -0.205986   \n",
            "1                -0.723379                -0.323878             -0.205986   \n",
            "2                 1.382402                -0.323878             -0.205986   \n",
            "3                -0.723379                -0.323878             -0.205986   \n",
            "4                -0.723379                -0.323878              4.854690   \n",
            "\n",
            "   smoking_history_former  smoking_history_never  \n",
            "0               -0.326620               1.337379  \n",
            "1               -0.326620               1.337379  \n",
            "2               -0.326620              -0.747731  \n",
            "3                3.061662              -0.747731  \n",
            "4               -0.326620              -0.747731  \n",
            "\n",
            "Standardized Testing Data (First 5 rows):\n",
            "        age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
            "0  0.590438     -0.289059      -0.205737  0.392782     0.610237   \n",
            "1 -1.368359     -0.289059      -0.205737  0.363327     0.209264   \n",
            "2 -1.234805     -0.289059      -0.205737 -0.589051     0.309507   \n",
            "3  0.723992     -0.289059      -0.205737  0.170888     0.710480   \n",
            "4  0.145256     -0.289059      -0.205737  0.245507     0.710480   \n",
            "\n",
            "   blood_glucose_level  diabetes  gender_Female  gender_Male  gender_Other  \\\n",
            "0            -1.429954 -0.310625       0.842074    -0.841770     -0.013251   \n",
            "1             0.653001 -0.310625      -1.187544     1.187973     -0.013251   \n",
            "2             0.282064 -0.310625      -1.187544     1.187973     -0.013251   \n",
            "3             0.653001 -0.310625       0.842074    -0.841770     -0.013251   \n",
            "4            -1.001949 -0.310625      -1.187544     1.187973     -0.013251   \n",
            "\n",
            "   smoking_history_No Info  smoking_history_current  smoking_history_ever  \\\n",
            "0                 1.382402                -0.323878             -0.205986   \n",
            "1                 1.382402                -0.323878             -0.205986   \n",
            "2                -0.723379                -0.323878             -0.205986   \n",
            "3                 1.382402                -0.323878             -0.205986   \n",
            "4                -0.723379                -0.323878             -0.205986   \n",
            "\n",
            "   smoking_history_former  smoking_history_never  \n",
            "0                -0.32662              -0.747731  \n",
            "1                -0.32662              -0.747731  \n",
            "2                -0.32662               1.337379  \n",
            "3                -0.32662              -0.747731  \n",
            "4                -0.32662               1.337379  \n"
          ]
        }
      ],
      "source": [
        "# 假设 X_train 和 X_test 是已经划分好的训练集和测试集（DataFrame格式）\n",
        "\n",
        "# 保存列名\n",
        "columns = X_train.columns\n",
        "\n",
        "# 初始化StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 对训练集进行标准化（fit + transform）\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# 对测试集进行标准化（仅 transform，防止数据泄漏）\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 转换回DataFrame，并指定列名\n",
        "X_train = pd.DataFrame(X_train, columns=columns)\n",
        "X_test = pd.DataFrame(X_test, columns=columns)\n",
        "\n",
        "# 输出标准化后的数据形状\n",
        "print(\"Standardized Training dataset features:\", X_train.shape)\n",
        "print(\"Standardized Testing dataset features:\", X_test.shape)\n",
        "\n",
        "# 打印标准化后的训练集和测试集的前五行\n",
        "print(\"\\nStandardized Training Data (First 5 rows):\")\n",
        "print(X_train.head())\n",
        "\n",
        "print(\"\\nStandardized Testing Data (First 5 rows):\")\n",
        "print(X_test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "重复样本数量: 18513\n"
          ]
        }
      ],
      "source": [
        "# 检查是否有重复行\n",
        "duplicates = X_train.index.isin(X_test.index)\n",
        "print(\"重复样本数量:\", sum(duplicates))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8WS3MgVZ3ym"
      },
      "source": [
        "# 模型的选择与训练\n",
        "Firstly we will select the right algorithm according to our requirement and then we will train data on model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Random Forest ===\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "F1-Score: 1.0000\n",
            "\n",
            "=== AdaBoost ===\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "F1-Score: 1.0000\n",
            "\n",
            "=== Gradient Boosting ===\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "F1-Score: 1.0000\n",
            "\n",
            "=== Bagging ===\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "F1-Score: 1.0000\n",
            "\n",
            "=== Extra Trees ===\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "F1-Score: 1.0000\n",
            "\n",
            "=== XGBoost ===\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "F1-Score: 1.0000\n",
            "\n",
            "=== Neural Network ===\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "F1-Score: 1.0000\n",
            "\n",
            "=== KNN ===\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "F1-Score: 1.0000\n",
            "\n",
            "=== Passive Aggressive ===\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "F1-Score: 1.0000\n",
            "\n",
            "=== CatBoost ===\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "F1-Score: 1.0000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
        "\n",
        "# 定义所有模型的配置（名称、模型类、参数）\n",
        "model_configs = [\n",
        "    {\n",
        "        'name': 'Random Forest',\n",
        "        'class': RandomForestClassifier,\n",
        "        'params': {'n_estimators': 50, 'random_state': 42}\n",
        "    },\n",
        "    {\n",
        "        'name': 'AdaBoost',\n",
        "        'class': AdaBoostClassifier,\n",
        "        'params': {'n_estimators': 50, 'random_state': 42}\n",
        "    },\n",
        "    {\n",
        "        'name': 'Gradient Boosting',\n",
        "        'class': GradientBoostingClassifier,\n",
        "        'params': {'n_estimators': 50, 'random_state': 42}\n",
        "    },\n",
        "    {\n",
        "        'name': 'Bagging',\n",
        "        'class': BaggingClassifier,\n",
        "        'params': {'n_estimators': 50, 'random_state': 42}\n",
        "    },\n",
        "    {\n",
        "        'name': 'Extra Trees',\n",
        "        'class': ExtraTreesClassifier,\n",
        "        'params': {'n_estimators': 50, 'random_state': 42}\n",
        "    },\n",
        "    {\n",
        "        'name': 'XGBoost',\n",
        "        'class': XGBClassifier,\n",
        "        'params': {'n_estimators': 50, 'random_state': 42}\n",
        "    },\n",
        "    {\n",
        "        'name': 'Neural Network',\n",
        "        'class': MLPClassifier,\n",
        "        'params': {'hidden_layer_sizes': (100, 50), 'max_iter': 200, 'random_state': 42}\n",
        "    },\n",
        "    {\n",
        "        'name': 'KNN',\n",
        "        'class': KNeighborsClassifier,\n",
        "        'params': {'n_neighbors': 6}\n",
        "    },\n",
        "    {\n",
        "        'name': 'Passive Aggressive',\n",
        "        'class': PassiveAggressiveClassifier,\n",
        "        'params': {'C': 1.0, 'random_state': 42}\n",
        "    },\n",
        "    {\n",
        "        'name': 'CatBoost',\n",
        "        'class': CatBoostClassifier,\n",
        "        'params': {'iterations': 50, 'learning_rate': 0.1, 'depth': 6, 'random_state': 42, 'verbose': 0}\n",
        "    }\n",
        "]\n",
        "\n",
        "# 统一训练并评估每个模型\n",
        "for config in model_configs:\n",
        "    model_name = config['name']\n",
        "    model = config['class'](**config['params'])\n",
        "    \n",
        "    # 训练模型\n",
        "    model.fit(X_train, Y_train)\n",
        "    \n",
        "    # 预测测试集\n",
        "    Y_pred = model.predict(X_test)\n",
        "    \n",
        "    # 计算指标\n",
        "    acc = accuracy_score(Y_test, Y_pred)\n",
        "    pre = precision_score(Y_test, Y_pred, average='weighted')  # 多分类使用 weighted\n",
        "    f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
        "    \n",
        "    # 打印结果\n",
        "    print(f\"\\n=== {model_name} ===\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"Precision: {pre:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of models and their names\n",
        "models = {\n",
        "    'random_forest': rf,\n",
        "    'adaboost': ab,\n",
        "    'gradient_boosting': gb,\n",
        "    'bagging': bagging,\n",
        "    'extra_trees': extra_trees,\n",
        "    'xgboost': xgboost,\n",
        "    'neural_network': nn_model,\n",
        "    'knn' :knn_model,\n",
        "    'pa': pa_model,\n",
        "    'catboost':catboost_model\n",
        "}\n",
        "\n",
        "# Save models\n",
        "for model_name, model in models.items():\n",
        "    dump(model, f'{model_name}_model.joblib')\n",
        "\n",
        "# Load models\n",
        "loaded_models = {}\n",
        "for model_name in models.keys():\n",
        "    loaded_models[model_name] = load(f'{model_name}_model.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用grid search来搜索最佳超参数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Best parameters for Random Forest: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
            "Best parameters for AdaBoost: {'learning_rate': 1.0, 'n_estimators': 200}\n",
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
            "Best parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
            "Best parameters for Bagging: {'max_features': 0.7, 'max_samples': 0.7, 'n_estimators': 100}\n",
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
            "Best parameters for Extra Trees: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
            "Best parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
            "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
            "Best parameters for Neural Network: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "Best parameters for Logistic Regression: {'C': 1.0, 'max_iter': 100, 'solver': 'liblinear'}\n"
          ]
        }
      ],
      "source": [
        "# 调参数\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Random Forest\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "rf_grid_search = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "rf_grid_search.fit(X_train, Y_train)\n",
        "print(\"Best parameters for Random Forest:\", rf_grid_search.best_params_)\n",
        "\n",
        "# AdaBoost\n",
        "ab_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1.0]\n",
        "}\n",
        "\n",
        "ab_grid_search = GridSearchCV(AdaBoostClassifier(), ab_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "ab_grid_search.fit(X_train, Y_train)\n",
        "print(\"Best parameters for AdaBoost:\", ab_grid_search.best_params_)\n",
        "\n",
        "# Gradient Boosting\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "    'max_depth': [3, 5, 7],\n",
        "}\n",
        "\n",
        "gb_grid_search = GridSearchCV(GradientBoostingClassifier(), gb_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "gb_grid_search.fit(X_train, Y_train)\n",
        "print(\"Best parameters for Gradient Boosting:\", gb_grid_search.best_params_)\n",
        "\n",
        "# Bagging\n",
        "bagging_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_samples': [0.5, 0.7, 1.0],\n",
        "    'max_features': [0.5, 0.7, 1.0]\n",
        "}\n",
        "\n",
        "bagging_grid_search = GridSearchCV(BaggingClassifier(), bagging_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "bagging_grid_search.fit(X_train, Y_train)\n",
        "print(\"Best parameters for Bagging:\", bagging_grid_search.best_params_)\n",
        "\n",
        "# Extra Trees\n",
        "extra_trees_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "extra_trees_grid_search = GridSearchCV(ExtraTreesClassifier(), extra_trees_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "extra_trees_grid_search.fit(X_train, Y_train)\n",
        "print(\"Best parameters for Extra Trees:\", extra_trees_grid_search.best_params_)\n",
        "\n",
        "# XGBoost\n",
        "xgboost_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "    'max_depth': [3, 5, 7],\n",
        "}\n",
        "\n",
        "xgboost_grid_search = GridSearchCV(XGBClassifier(), xgboost_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "xgboost_grid_search.fit(X_train, Y_train)\n",
        "print(\"Best parameters for XGBoost:\", xgboost_grid_search.best_params_)\n",
        "\n",
        "# Neural Network (MLP)\n",
        "nn_param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'alpha': [0.0001, 0.001],\n",
        "    'learning_rate_init': [0.001, 0.01]\n",
        "}\n",
        "\n",
        "nn_grid_search = GridSearchCV(MLPClassifier(max_iter=1000), nn_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "nn_grid_search.fit(X_train, Y_train)\n",
        "print(\"Best parameters for Neural Network:\", nn_grid_search.best_params_)\n",
        "\n",
        "# 定义超参数搜索空间 / Define hyperparameter search space\n",
        "knn_param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 10], \n",
        "    'weights': ['uniform', 'distance'], \n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
        "    'leaf_size': [30, 40, 50],  \n",
        "    'p': [1, 2],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski'] \n",
        "}\n",
        "\n",
        "# 使用 GridSearchCV 进行超参数调优 / use gridsearch to tuning the hyperparameter   \n",
        "knn_grid_search = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "knn_grid_search.fit(X_train, Y_train)\n",
        "\n",
        "# 1. PassiveAggressiveClassifier Hyperparameter Tuning\n",
        "pa_param_grid = {\n",
        "    'C': [0.1, 0.5, 1.0, 5.0],  # Regularization parameter\n",
        "    'max_iter': [50, 100, 200],  # Maximum number of iterations\n",
        "    'tol': [1e-4, 1e-3],  # Tolerance for stopping criteria\n",
        "}\n",
        "\n",
        "pa_grid_search = GridSearchCV(PassiveAggressiveClassifier(random_state=42), \n",
        "                              pa_param_grid, \n",
        "                              cv=3,  # 3-fold cross-validation\n",
        "                              n_jobs=-1,  # Use all available CPUs\n",
        "                              verbose=2)\n",
        "\n",
        "pa_grid_search.fit(X_train, Y_train)\n",
        "\n",
        "# 2. CatBoostClassifier Hyperparameter Tuning\n",
        "catboost_param_grid = {\n",
        "    'iterations': [100, 200],  # Number of boosting iterations\n",
        "    'learning_rate': [0.01, 0.1, 0.2],  # Learning rate\n",
        "    'depth': [4, 6, 8],  # Depth of the trees\n",
        "    'l2_leaf_reg': [1, 3, 5],  # L2 regularization term\n",
        "}\n",
        "\n",
        "catboost_grid_search = GridSearchCV(CatBoostClassifier(random_state=42, verbose=0), \n",
        "                                    catboost_param_grid, \n",
        "                                    cv=3,  # 3-fold cross-validation\n",
        "                                    n_jobs=-1,  # Use all available CPUs\n",
        "                                    verbose=2)\n",
        "\n",
        "catboost_grid_search.fit(X_train, Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Anconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.92500619 0.92309237 0.92500619 0.92309237 0.9290499  0.92767627\n",
            " 0.9290499  0.92767627 0.93023833 0.92920425 0.93023833 0.92920425\n",
            " 0.93134955 0.93023831 0.93134955 0.93023831 0.92446599 0.92210458\n",
            " 0.92446599 0.92210458 0.9288647  0.92687371 0.9288647  0.92687371\n",
            " 0.9308248  0.92940486 0.9308248  0.92940486 0.93124153 0.92992963\n",
            " 0.93124153 0.92992963 0.92446599 0.92210458 0.92500619 0.92309237\n",
            " 0.9288647  0.92687371 0.9290499  0.92767627 0.9308248  0.92940486\n",
            " 0.93023833 0.92920425 0.93124153 0.92992963 0.93134955 0.93023831\n",
            " 0.92500619 0.92309237 0.92500619 0.92309237 0.9290499  0.92767627\n",
            " 0.9290499  0.92767627 0.93023833 0.92920425 0.93023833 0.92920425\n",
            " 0.93134955 0.93023831 0.93134955 0.93023831 0.92446599 0.92210458\n",
            " 0.92446599 0.92210458 0.9288647  0.92687371 0.9288647  0.92687371\n",
            " 0.9308248  0.92940486 0.9308248  0.92940486 0.93124153 0.92992963\n",
            " 0.93124153 0.92992963 0.92446599 0.92210458 0.92500619 0.92309237\n",
            " 0.9288647  0.92687371 0.9290499  0.92767627 0.9308248  0.92940486\n",
            " 0.93023833 0.92920425 0.93124153 0.92992963 0.93134955 0.93023831\n",
            " 0.92500619 0.9230615  0.92500619 0.9230615  0.9290036  0.92770714\n",
            " 0.9290036  0.92770714 0.93017659 0.92914251 0.93017659 0.92914251\n",
            " 0.93128782 0.93023831 0.93128782 0.93023831 0.92458946 0.92221262\n",
            " 0.92458946 0.92221262 0.9288184  0.92684284 0.9288184  0.92684284\n",
            " 0.93076307 0.92934313 0.93076307 0.92934313 0.93124153 0.92999136\n",
            " 0.93124153 0.92999136 0.92458946 0.92221262 0.92500619 0.9230615\n",
            " 0.9288184  0.92684284 0.9290036  0.92770714 0.93076307 0.92934313\n",
            " 0.93017659 0.92914251 0.93124153 0.92999136 0.93128782 0.93023831\n",
            " 0.92499075 0.92309237 0.92499075 0.92309237 0.92911163 0.92772257\n",
            " 0.92911163 0.92772257 0.93022289 0.92926598 0.93022289 0.92926598\n",
            " 0.93134955 0.93031548 0.93134955 0.93031548 0.92446599 0.92205828\n",
            " 0.92446599 0.92205828 0.92897274 0.92701261 0.92897274 0.92701261\n",
            " 0.93076307 0.92937399 0.93076307 0.92937399 0.93128783 0.9299605\n",
            " 0.93128783 0.9299605  0.92446599 0.92205828 0.92499075 0.92309237\n",
            " 0.92897274 0.92701261 0.92911163 0.92772257 0.93076307 0.92937399\n",
            " 0.93022289 0.92926598 0.93128783 0.9299605  0.93134955 0.93031548\n",
            " 0.92499075 0.92309237 0.92499075 0.92309237 0.92911163 0.92772257\n",
            " 0.92911163 0.92772257 0.93022289 0.92926598 0.93022289 0.92926598\n",
            " 0.93134955 0.93031548 0.93134955 0.93031548 0.92446599 0.92205828\n",
            " 0.92446599 0.92205828 0.92897274 0.92701261 0.92897274 0.92701261\n",
            " 0.93076307 0.92937399 0.93076307 0.92937399 0.93128783 0.9299605\n",
            " 0.93128783 0.9299605  0.92446599 0.92205828 0.92499075 0.92309237\n",
            " 0.92897274 0.92701261 0.92911163 0.92772257 0.93076307 0.92937399\n",
            " 0.93022289 0.92926598 0.93128783 0.9299605  0.93134955 0.93031548\n",
            " 0.92506792 0.9231078  0.92506792 0.9231078  0.9290499  0.92772257\n",
            " 0.9290499  0.92772257 0.93017659 0.92915794 0.93017659 0.92915794\n",
            " 0.93138042 0.93034634 0.93138042 0.93034634 0.92445056 0.92204285\n",
            " 0.92445056 0.92204285 0.9288647  0.92687371 0.9288647  0.92687371\n",
            " 0.93076307 0.92932769 0.93076307 0.92932769 0.93125696 0.92999136\n",
            " 0.93125696 0.92999136 0.92445056 0.92204285 0.92506792 0.9231078\n",
            " 0.9288647  0.92687371 0.9290499  0.92772257 0.93076307 0.92932769\n",
            " 0.93017659 0.92915794 0.93125696 0.92999136 0.93138042 0.93034634\n",
            " 0.92500619 0.92309237 0.92500619 0.92309237 0.9290499  0.92767627\n",
            " 0.9290499  0.92767627 0.93023833 0.92920425 0.93023833 0.92920425\n",
            " 0.93134955 0.93023831 0.93134955 0.93023831 0.92446599 0.92210458\n",
            " 0.92446599 0.92210458 0.9288647  0.92687371 0.9288647  0.92687371\n",
            " 0.9308248  0.92940486 0.9308248  0.92940486 0.93124153 0.92992963\n",
            " 0.93124153 0.92992963 0.92446599 0.92210458 0.92500619 0.92309237\n",
            " 0.9288647  0.92687371 0.9290499  0.92767627 0.9308248  0.92940486\n",
            " 0.93023833 0.92920425 0.93124153 0.92992963 0.93134955 0.93023831\n",
            " 0.92500619 0.92309237 0.92500619 0.92309237 0.9290499  0.92767627\n",
            " 0.9290499  0.92767627 0.93023833 0.92920425 0.93023833 0.92920425\n",
            " 0.93134955 0.93023831 0.93134955 0.93023831 0.92446599 0.92210458\n",
            " 0.92446599 0.92210458 0.9288647  0.92687371 0.9288647  0.92687371\n",
            " 0.9308248  0.92940486 0.9308248  0.92940486 0.93124153 0.92992963\n",
            " 0.93124153 0.92992963 0.92446599 0.92210458 0.92500619 0.92309237\n",
            " 0.9288647  0.92687371 0.9290499  0.92767627 0.9308248  0.92940486\n",
            " 0.93023833 0.92920425 0.93124153 0.92992963 0.93134955 0.93023831\n",
            " 0.92500619 0.9230615  0.92500619 0.9230615  0.9290036  0.92770714\n",
            " 0.9290036  0.92770714 0.93017659 0.92914251 0.93017659 0.92914251\n",
            " 0.93128782 0.93023831 0.93128782 0.93023831 0.92458946 0.92221262\n",
            " 0.92458946 0.92221262 0.9288184  0.92684284 0.9288184  0.92684284\n",
            " 0.93076307 0.92934313 0.93076307 0.92934313 0.93124153 0.92999136\n",
            " 0.93124153 0.92999136 0.92458946 0.92221262 0.92500619 0.9230615\n",
            " 0.9288184  0.92684284 0.9290036  0.92770714 0.93076307 0.92934313\n",
            " 0.93017659 0.92914251 0.93124153 0.92999136 0.93128782 0.93023831\n",
            "        nan 0.92299977        nan 0.92299977        nan 0.92767627\n",
            "        nan 0.92767627        nan 0.92921968        nan 0.92921968\n",
            "        nan 0.93022287        nan 0.93022287        nan 0.92221262\n",
            "        nan 0.92221262        nan 0.92693544        nan 0.92693544\n",
            "        nan 0.92943573        nan 0.92943573        nan 0.92991419\n",
            "        nan 0.92991419        nan 0.92221262        nan 0.92299977\n",
            "        nan 0.92693544        nan 0.92767627        nan 0.92943573\n",
            "        nan 0.92921968        nan 0.92991419        nan 0.93022287\n",
            "        nan 0.92299977        nan 0.92299977        nan 0.92767627\n",
            "        nan 0.92767627        nan 0.92921968        nan 0.92921968\n",
            "        nan 0.93022287        nan 0.93022287        nan 0.92221262\n",
            "        nan 0.92221262        nan 0.92693544        nan 0.92693544\n",
            "        nan 0.92943573        nan 0.92943573        nan 0.92991419\n",
            "        nan 0.92991419        nan 0.92221262        nan 0.92299977\n",
            "        nan 0.92693544        nan 0.92767627        nan 0.92943573\n",
            "        nan 0.92921968        nan 0.92991419        nan 0.93022287\n",
            "        nan 0.92299977        nan 0.92299977        nan 0.92767627\n",
            "        nan 0.92767627        nan 0.92921968        nan 0.92921968\n",
            "        nan 0.93022287        nan 0.93022287        nan 0.92221262\n",
            "        nan 0.92221262        nan 0.92693544        nan 0.92693544\n",
            "        nan 0.92943573        nan 0.92943573        nan 0.92991419\n",
            "        nan 0.92991419        nan 0.92221262        nan 0.92299977\n",
            "        nan 0.92693544        nan 0.92767627        nan 0.92943573\n",
            "        nan 0.92921968        nan 0.92991419        nan 0.93022287]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
              "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
              "                         &#x27;leaf_size&#x27;: [30, 40, 50],\n",
              "                         &#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;manhattan&#x27;, &#x27;minkowski&#x27;],\n",
              "                         &#x27;n_neighbors&#x27;: [3, 5, 7, 10], &#x27;p&#x27;: [1, 2],\n",
              "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
              "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
              "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
              "                         &#x27;leaf_size&#x27;: [30, 40, 50],\n",
              "                         &#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;manhattan&#x27;, &#x27;minkowski&#x27;],\n",
              "                         &#x27;n_neighbors&#x27;: [3, 5, 7, 10], &#x27;p&#x27;: [1, 2],\n",
              "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
              "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=3, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
              "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
              "                         'leaf_size': [30, 40, 50],\n",
              "                         'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
              "                         'n_neighbors': [3, 5, 7, 10], 'p': [1, 2],\n",
              "                         'weights': ['uniform', 'distance']},\n",
              "             verbose=2)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # 定义超参数搜索空间 / Define hyperparameter search space\n",
        "# knn_param_grid = {\n",
        "#     'n_neighbors': [3, 5, 7, 10], \n",
        "#     'weights': ['uniform', 'distance'], \n",
        "#     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
        "#     'leaf_size': [30, 40, 50],  \n",
        "#     'p': [1, 2],\n",
        "#     'metric': ['euclidean', 'manhattan', 'minkowski'] \n",
        "# }\n",
        "\n",
        "# # 使用 GridSearchCV 进行超参数调优 / use gridsearch to tuning the hyperparameter   \n",
        "# knn_grid_search = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "# knn_grid_search.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.6149196\ttotal: 179ms\tremaining: 17.7s\n",
            "1:\tlearn: 0.5525773\ttotal: 202ms\tremaining: 9.88s\n",
            "2:\tlearn: 0.4997951\ttotal: 219ms\tremaining: 7.07s\n",
            "3:\tlearn: 0.4541066\ttotal: 235ms\tremaining: 5.65s\n",
            "4:\tlearn: 0.4158865\ttotal: 250ms\tremaining: 4.76s\n",
            "5:\tlearn: 0.3825441\ttotal: 267ms\tremaining: 4.18s\n",
            "6:\tlearn: 0.3540754\ttotal: 282ms\tremaining: 3.74s\n",
            "7:\tlearn: 0.3283944\ttotal: 294ms\tremaining: 3.38s\n",
            "8:\tlearn: 0.3071990\ttotal: 313ms\tremaining: 3.16s\n",
            "9:\tlearn: 0.2880267\ttotal: 329ms\tremaining: 2.96s\n",
            "10:\tlearn: 0.2711083\ttotal: 344ms\tremaining: 2.79s\n",
            "11:\tlearn: 0.2558394\ttotal: 357ms\tremaining: 2.62s\n",
            "12:\tlearn: 0.2431363\ttotal: 373ms\tremaining: 2.5s\n",
            "13:\tlearn: 0.2317804\ttotal: 389ms\tremaining: 2.39s\n",
            "14:\tlearn: 0.2205197\ttotal: 406ms\tremaining: 2.3s\n",
            "15:\tlearn: 0.2105996\ttotal: 426ms\tremaining: 2.23s\n",
            "16:\tlearn: 0.2025158\ttotal: 442ms\tremaining: 2.16s\n",
            "17:\tlearn: 0.1941065\ttotal: 463ms\tremaining: 2.11s\n",
            "18:\tlearn: 0.1872991\ttotal: 481ms\tremaining: 2.05s\n",
            "19:\tlearn: 0.1812648\ttotal: 497ms\tremaining: 1.99s\n",
            "20:\tlearn: 0.1756688\ttotal: 513ms\tremaining: 1.93s\n",
            "21:\tlearn: 0.1705098\ttotal: 529ms\tremaining: 1.88s\n",
            "22:\tlearn: 0.1658268\ttotal: 544ms\tremaining: 1.82s\n",
            "23:\tlearn: 0.1621866\ttotal: 559ms\tremaining: 1.77s\n",
            "24:\tlearn: 0.1582293\ttotal: 575ms\tremaining: 1.72s\n",
            "25:\tlearn: 0.1547723\ttotal: 591ms\tremaining: 1.68s\n",
            "26:\tlearn: 0.1515878\ttotal: 609ms\tremaining: 1.65s\n",
            "27:\tlearn: 0.1485484\ttotal: 630ms\tremaining: 1.62s\n",
            "28:\tlearn: 0.1456145\ttotal: 648ms\tremaining: 1.58s\n",
            "29:\tlearn: 0.1433689\ttotal: 666ms\tremaining: 1.55s\n",
            "30:\tlearn: 0.1411037\ttotal: 685ms\tremaining: 1.52s\n",
            "31:\tlearn: 0.1393534\ttotal: 702ms\tremaining: 1.49s\n",
            "32:\tlearn: 0.1373192\ttotal: 719ms\tremaining: 1.46s\n",
            "33:\tlearn: 0.1356076\ttotal: 734ms\tremaining: 1.42s\n",
            "34:\tlearn: 0.1341018\ttotal: 751ms\tremaining: 1.39s\n",
            "35:\tlearn: 0.1327394\ttotal: 768ms\tremaining: 1.37s\n",
            "36:\tlearn: 0.1315985\ttotal: 784ms\tremaining: 1.33s\n",
            "37:\tlearn: 0.1307165\ttotal: 801ms\tremaining: 1.31s\n",
            "38:\tlearn: 0.1297193\ttotal: 817ms\tremaining: 1.28s\n",
            "39:\tlearn: 0.1288278\ttotal: 833ms\tremaining: 1.25s\n",
            "40:\tlearn: 0.1279042\ttotal: 851ms\tremaining: 1.23s\n",
            "41:\tlearn: 0.1271607\ttotal: 869ms\tremaining: 1.2s\n",
            "42:\tlearn: 0.1261955\ttotal: 890ms\tremaining: 1.18s\n",
            "43:\tlearn: 0.1253192\ttotal: 908ms\tremaining: 1.16s\n",
            "44:\tlearn: 0.1246189\ttotal: 926ms\tremaining: 1.13s\n",
            "45:\tlearn: 0.1241499\ttotal: 942ms\tremaining: 1.1s\n",
            "46:\tlearn: 0.1235569\ttotal: 956ms\tremaining: 1.08s\n",
            "47:\tlearn: 0.1231106\ttotal: 971ms\tremaining: 1.05s\n",
            "48:\tlearn: 0.1223799\ttotal: 988ms\tremaining: 1.03s\n",
            "49:\tlearn: 0.1218159\ttotal: 1s\tremaining: 1s\n",
            "50:\tlearn: 0.1211738\ttotal: 1.02s\tremaining: 982ms\n",
            "51:\tlearn: 0.1208709\ttotal: 1.04s\tremaining: 960ms\n",
            "52:\tlearn: 0.1204808\ttotal: 1.06s\tremaining: 941ms\n",
            "53:\tlearn: 0.1202313\ttotal: 1.08s\tremaining: 919ms\n",
            "54:\tlearn: 0.1197838\ttotal: 1.09s\tremaining: 896ms\n",
            "55:\tlearn: 0.1193033\ttotal: 1.11s\tremaining: 873ms\n",
            "56:\tlearn: 0.1189697\ttotal: 1.13s\tremaining: 850ms\n",
            "57:\tlearn: 0.1185588\ttotal: 1.14s\tremaining: 828ms\n",
            "58:\tlearn: 0.1182647\ttotal: 1.16s\tremaining: 806ms\n",
            "59:\tlearn: 0.1180627\ttotal: 1.18s\tremaining: 784ms\n",
            "60:\tlearn: 0.1177463\ttotal: 1.19s\tremaining: 763ms\n",
            "61:\tlearn: 0.1172260\ttotal: 1.21s\tremaining: 741ms\n",
            "62:\tlearn: 0.1171077\ttotal: 1.23s\tremaining: 721ms\n",
            "63:\tlearn: 0.1169236\ttotal: 1.24s\tremaining: 699ms\n",
            "64:\tlearn: 0.1165088\ttotal: 1.26s\tremaining: 679ms\n",
            "65:\tlearn: 0.1163100\ttotal: 1.28s\tremaining: 659ms\n",
            "66:\tlearn: 0.1161491\ttotal: 1.29s\tremaining: 638ms\n",
            "67:\tlearn: 0.1159995\ttotal: 1.31s\tremaining: 617ms\n",
            "68:\tlearn: 0.1158699\ttotal: 1.33s\tremaining: 598ms\n",
            "69:\tlearn: 0.1156298\ttotal: 1.35s\tremaining: 579ms\n",
            "70:\tlearn: 0.1154896\ttotal: 1.37s\tremaining: 559ms\n",
            "71:\tlearn: 0.1154188\ttotal: 1.38s\tremaining: 538ms\n",
            "72:\tlearn: 0.1153166\ttotal: 1.4s\tremaining: 518ms\n",
            "73:\tlearn: 0.1152437\ttotal: 1.42s\tremaining: 498ms\n",
            "74:\tlearn: 0.1150670\ttotal: 1.43s\tremaining: 478ms\n",
            "75:\tlearn: 0.1149550\ttotal: 1.45s\tremaining: 458ms\n",
            "76:\tlearn: 0.1148346\ttotal: 1.47s\tremaining: 439ms\n",
            "77:\tlearn: 0.1147727\ttotal: 1.49s\tremaining: 419ms\n",
            "78:\tlearn: 0.1146015\ttotal: 1.5s\tremaining: 399ms\n",
            "79:\tlearn: 0.1145256\ttotal: 1.52s\tremaining: 379ms\n",
            "80:\tlearn: 0.1144240\ttotal: 1.53s\tremaining: 359ms\n",
            "81:\tlearn: 0.1143749\ttotal: 1.55s\tremaining: 340ms\n",
            "82:\tlearn: 0.1142247\ttotal: 1.56s\tremaining: 321ms\n",
            "83:\tlearn: 0.1141378\ttotal: 1.58s\tremaining: 301ms\n",
            "84:\tlearn: 0.1140475\ttotal: 1.6s\tremaining: 282ms\n",
            "85:\tlearn: 0.1140008\ttotal: 1.61s\tremaining: 263ms\n",
            "86:\tlearn: 0.1139251\ttotal: 1.63s\tremaining: 244ms\n",
            "87:\tlearn: 0.1138001\ttotal: 1.65s\tremaining: 225ms\n",
            "88:\tlearn: 0.1137297\ttotal: 1.67s\tremaining: 206ms\n",
            "89:\tlearn: 0.1136444\ttotal: 1.68s\tremaining: 187ms\n",
            "90:\tlearn: 0.1135740\ttotal: 1.7s\tremaining: 168ms\n",
            "91:\tlearn: 0.1135292\ttotal: 1.72s\tremaining: 150ms\n",
            "92:\tlearn: 0.1134565\ttotal: 1.74s\tremaining: 131ms\n",
            "93:\tlearn: 0.1134094\ttotal: 1.75s\tremaining: 112ms\n",
            "94:\tlearn: 0.1133405\ttotal: 1.77s\tremaining: 93.2ms\n",
            "95:\tlearn: 0.1132702\ttotal: 1.79s\tremaining: 74.5ms\n",
            "96:\tlearn: 0.1132416\ttotal: 1.81s\tremaining: 55.9ms\n",
            "97:\tlearn: 0.1130361\ttotal: 1.82s\tremaining: 37.2ms\n",
            "98:\tlearn: 0.1129676\ttotal: 1.84s\tremaining: 18.6ms\n",
            "99:\tlearn: 0.1129218\ttotal: 1.86s\tremaining: 0us\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x1ac905e0050>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#PassiveAggressiveClassifier 需不需要使用这个用这个的话这是基模型还是其他的 / Do you need to use this? If so, is this the base model or something else\n",
        "pa_classifier = PassiveAggressiveClassifier(C=1.0, random_state=42)\n",
        "pa_classifier.fit(X_train, Y_train)\n",
        "\n",
        "#CatBoostClassifier\n",
        "catboost_model = CatBoostClassifier(iterations=100,  # Number of boosting iterations (adjust as needed)\n",
        "                                    learning_rate=0.1,  # Learning rate (adjust as needed)\n",
        "                                    depth=6,  # Depth of the trees (adjust as needed)\n",
        "                                    random_state=42)  # Random seed for reproducibility\n",
        "\n",
        "catboost_model.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Anconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters for PassiveAggressiveClassifier: {'C': 0.1, 'max_iter': 50, 'tol': 0.0001}\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best Parameters for CatBoostClassifier: {'depth': 6, 'iterations': 100, 'l2_leaf_reg': 3, 'learning_rate': 0.1}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['best_catboost_model.pkl']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# 1. PassiveAggressiveClassifier Hyperparameter Tuning\n",
        "pa_param_grid = {\n",
        "    'C': [0.1, 0.5, 1.0, 5.0],  # Regularization parameter\n",
        "    'max_iter': [50, 100, 200],  # Maximum number of iterations\n",
        "    'tol': [1e-4, 1e-3],  # Tolerance for stopping criteria\n",
        "}\n",
        "\n",
        "pa_grid_search = GridSearchCV(PassiveAggressiveClassifier(random_state=42), \n",
        "                              pa_param_grid, \n",
        "                              cv=3,  # 3-fold cross-validation\n",
        "                              n_jobs=-1,  # Use all available CPUs\n",
        "                              verbose=2)\n",
        "\n",
        "pa_grid_search.fit(X_train, Y_train)\n",
        "\n",
        "# Print the best parameters for PassiveAggressiveClassifier\n",
        "print(\"Best Parameters for PassiveAggressiveClassifier:\", pa_grid_search.best_params_)\n",
        "\n",
        "# Save the best model (PassiveAggressiveClassifier)\n",
        "best_pa_model = pa_grid_search.best_estimator_\n",
        "joblib.dump(best_pa_model, 'best_pa_model.pkl')  # Save to file\n",
        "\n",
        "# 2. CatBoostClassifier Hyperparameter Tuning\n",
        "catboost_param_grid = {\n",
        "    'iterations': [100, 200],  # Number of boosting iterations\n",
        "    'learning_rate': [0.01, 0.1, 0.2],  # Learning rate\n",
        "    'depth': [4, 6, 8],  # Depth of the trees\n",
        "    'l2_leaf_reg': [1, 3, 5],  # L2 regularization term\n",
        "}\n",
        "\n",
        "catboost_grid_search = GridSearchCV(CatBoostClassifier(random_state=42, verbose=0), \n",
        "                                    catboost_param_grid, \n",
        "                                    cv=3,  # 3-fold cross-validation\n",
        "                                    n_jobs=-1,  # Use all available CPUs\n",
        "                                    verbose=2)\n",
        "\n",
        "catboost_grid_search.fit(X_train, Y_train)\n",
        "\n",
        "# Print the best parameters for CatBoostClassifier\n",
        "print(\"Best Parameters for CatBoostClassifier:\", catboost_grid_search.best_params_)\n",
        "\n",
        "# Save the best model (CatBoostClassifier)\n",
        "best_catboost_model = catboost_grid_search.best_estimator_\n",
        "joblib.dump(best_catboost_model, 'best_catboost_model.pkl')  # Save to file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 保存最佳超参数模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best models saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# 保存最佳模型 save best model - Random Forest\n",
        "best_rf = rf_grid_search.best_estimator_\n",
        "joblib.dump(best_rf, 'best_random_forest_model.pkl')\n",
        "\n",
        "# 保存最佳模型 / save best model  - AdaBoost\n",
        "best_ab = ab_grid_search.best_estimator_\n",
        "joblib.dump(best_ab, 'best_adaboost_model.pkl')\n",
        "\n",
        "# 保存最佳模型 / save best model  - Gradient Boosting\n",
        "best_gb = gb_grid_search.best_estimator_\n",
        "joblib.dump(best_gb, 'best_gradient_boosting_model.pkl')\n",
        "\n",
        "# 保存最佳模型 / save best model - Bagging\n",
        "best_bagging = bagging_grid_search.best_estimator_\n",
        "joblib.dump(best_bagging, 'best_bagging_model.pkl')\n",
        "\n",
        "# 保存最佳模型 / save best model - Extra Trees\n",
        "best_extra_trees = extra_trees_grid_search.best_estimator_\n",
        "joblib.dump(best_extra_trees, 'best_extra_trees_model.pkl')\n",
        "\n",
        "# 保存最佳模型 / save best model- XGBoost\n",
        "best_xgboost = xgboost_grid_search.best_estimator_\n",
        "joblib.dump(best_xgboost, 'best_xgboost_model.pkl')\n",
        "\n",
        "# 保存最佳模型 save best model - Neural Network (MLP)\n",
        "best_nn = nn_grid_search.best_estimator_\n",
        "joblib.dump(best_nn, 'best_nn_model.pkl')\n",
        "\n",
        "# 保存最佳模型 save best model - KNN\n",
        "best_knn = knn_grid_search.best_estimator_\n",
        "joblib.dump(best_knn,'best_knn_model.pkl')\n",
        "\n",
        "# Save the best model (PassiveAggressiveClassifier)\n",
        "best_pa_model = pa_grid_search.best_estimator_\n",
        "joblib.dump(best_pa_model, 'best_pa_model.pkl')  # Save to file\n",
        "\n",
        "# Save the best model (CatBoostClassifier)\n",
        "best_catboost_model = catboost_grid_search.best_estimator_\n",
        "joblib.dump(best_catboost_model, 'best_catboost_model.pkl')  # Save to file\n",
        "\n",
        "print(\"Best models saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKNJDFSoaXK2"
      },
      "source": [
        "# Model Testing / 模型测试"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Random Forest with best parameters: 0.9499441823616263\n",
            "Accuracy for AdaBoost with best parameters: 0.9528971154884943\n",
            "Accuracy for Gradient Boosting with best parameters: 0.9530411610068782\n",
            "Accuracy for Bagging with best parameters: 0.9510605351291008\n",
            "Accuracy for Extra Trees with best parameters: 0.9473513630307177\n",
            "Accuracy for XGBoost with best parameters: 0.9530051496272822\n",
            "Accuracy for Neural Network with best parameters: 0.9489718751125356\n",
            "Accuracy for KNN with best parameters: 0.9311822535921351\n"
          ]
        }
      ],
      "source": [
        "# Random Forest\n",
        "best_rf = rf_grid_search.best_estimator_\n",
        "rf_accuracy = best_rf.score(X_test, Y_test)\n",
        "print(\"Accuracy for Random Forest with best parameters:\", rf_accuracy)\n",
        "\n",
        "# AdaBoost\n",
        "best_ab = ab_grid_search.best_estimator_\n",
        "ab_accuracy = best_ab.score(X_test, Y_test)\n",
        "print(\"Accuracy for AdaBoost with best parameters:\", ab_accuracy)\n",
        "\n",
        "# Gradient Boosting\n",
        "best_gb = gb_grid_search.best_estimator_\n",
        "gb_accuracy = best_gb.score(X_test, Y_test)\n",
        "print(\"Accuracy for Gradient Boosting with best parameters:\", gb_accuracy)\n",
        "\n",
        "# Bagging\n",
        "best_bagging = bagging_grid_search.best_estimator_\n",
        "bagging_accuracy = best_bagging.score(X_test, Y_test)\n",
        "print(\"Accuracy for Bagging with best parameters:\", bagging_accuracy)\n",
        "\n",
        "# Extra Trees\n",
        "best_extra_trees = extra_trees_grid_search.best_estimator_\n",
        "extra_trees_accuracy = best_extra_trees.score(X_test, Y_test)\n",
        "print(\"Accuracy for Extra Trees with best parameters:\", extra_trees_accuracy)\n",
        "\n",
        "# XGBoost\n",
        "best_xgboost = xgboost_grid_search.best_estimator_\n",
        "xgboost_accuracy = best_xgboost.score(X_test, Y_test)\n",
        "print(\"Accuracy for XGBoost with best parameters:\", xgboost_accuracy)\n",
        "\n",
        "# Neural Network (MLP)\n",
        "best_nn = nn_grid_search.best_estimator_\n",
        "nn_accuracy = best_nn.score(X_test, Y_test)\n",
        "print(\"Accuracy for Neural Network with best parameters:\", nn_accuracy)\n",
        "\n",
        "# KNN\n",
        "best_knn = knn_grid_search.best_estimator_\n",
        "knn_accuracy = best_knn.score(X_test, Y_test)\n",
        "print(\"Accuracy for KNN with best parameters:\", knn_accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Accuracy for Best PassiveAggressiveClassifier Model: 0.9179300659008247\n",
            "Test Set Accuracy for Best CatBoostClassifier Model: 0.9536533544600093\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the best PassiveAggressiveClassifier model\n",
        "best_pa_model = joblib.load('best_pa_model.pkl')\n",
        "\n",
        "# Make predictions on the test set for PassiveAggressiveClassifier\n",
        "pa_predictions = best_pa_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for PassiveAggressiveClassifier\n",
        "pa_accuracy = accuracy_score(Y_test, pa_predictions)\n",
        "print(f\"Test Set Accuracy for Best PassiveAggressiveClassifier Model: {pa_accuracy}\")\n",
        "\n",
        "# 2. Load the best CatBoostClassifier model\n",
        "best_catboost_model = joblib.load('best_catboost_model.pkl')\n",
        "\n",
        "# Make predictions on the test set for CatBoostClassifier\n",
        "catboost_predictions = best_catboost_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for CatBoostClassifier\n",
        "catboost_accuracy = accuracy_score(Y_test, catboost_predictions)\n",
        "print(f\"Test Set Accuracy for Best CatBoostClassifier Model: {catboost_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 组合为Hybrid模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 使用stack方法将Gradient Boosting, XGBoost, Catboost 组合为hybrid模型 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Accuracy for Stacking Model: 0.952392956174151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Anconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression  # 作为元学习器\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# 加载模型\n",
        "best_gb_model = joblib.load('best_gradient_boosting_model.pkl')  # Gradient Boosting\n",
        "best_xgboost_model = joblib.load('best_xgboost_model.pkl')  # XGBoost\n",
        "best_catboost_model = joblib.load('best_catboost_model.pkl')  # CatBoost\n",
        "\n",
        "# 定义基学习器\n",
        "base_learners = [\n",
        "    ('gb', best_gb_model), \n",
        "    ('xgb', best_xgboost_model), \n",
        "    ('cat', best_catboost_model)\n",
        "]\n",
        "\n",
        "# 使用逻辑回归作为元学习器\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# 构建 StackingClassifier\n",
        "stacking_model3 = StackingClassifier(\n",
        "    estimators=base_learners, \n",
        "    final_estimator=meta_learner, \n",
        "    passthrough=True  # 让元学习器直接访问原始特征\n",
        ")\n",
        "\n",
        "# 训练 Stacking 模型\n",
        "stacking_model3.fit(X_train, Y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.使用voting方法将Gradient Boosting, XGBoost, Catboost 组合为hybrid模型 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Accuracy for Voting Model: 0.953149195145666\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 加载模型\n",
        "best_gb_model = joblib.load('best_gradient_boosting_model.pkl')  # Gradient Boosting\n",
        "best_xgboost_model = joblib.load('best_xgboost_model.pkl')  # XGBoost\n",
        "best_catboost_model = joblib.load('best_catboost_model.pkl')  # CatBoost\n",
        "\n",
        "# 定义基学习器\n",
        "base_learners = [\n",
        "    ('gb', best_gb_model), \n",
        "    ('xgb', best_xgboost_model), \n",
        "    ('cat', best_catboost_model)\n",
        "]\n",
        "\n",
        "# 使用 VotingClassifier 进行投票融合\n",
        "voting_model3 = VotingClassifier(\n",
        "    estimators=base_learners, \n",
        "    voting='soft'  # 软投票，可以改为 'hard' 使用硬投票\n",
        ")\n",
        "\n",
        "# 训练 Voting 模型\n",
        "voting_model3.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. 使用stack方法将Gradient Boosting, XGBoost, Catboost 和Adaboost 组合为hybrid模型 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Anconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Accuracy for Stacking Model: 0.9525730130721308\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 加载模型\n",
        "best_gb_model = joblib.load('best_gradient_boosting_model.pkl')  # Gradient Boosting\n",
        "best_xgboost_model = joblib.load('best_xgboost_model.pkl')  # XGBoost\n",
        "best_catboost_model = joblib.load('best_catboost_model.pkl')  # CatBoost\n",
        "best_adaboost_model = joblib.load('best_adaboost_model.pkl')  # AdaBoost\n",
        "\n",
        "# 定义基学习器\n",
        "base_learners = [\n",
        "    ('gb', best_gb_model),\n",
        "    ('xgb', best_xgboost_model),\n",
        "    ('cat', best_catboost_model),\n",
        "    ('ab', best_adaboost_model)\n",
        "]\n",
        "\n",
        "# 选择逻辑回归作为元学习器\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# 构建 StackingClassifier\n",
        "stacking_model4 = StackingClassifier(\n",
        "    estimators=base_learners, \n",
        "    final_estimator=meta_learner, \n",
        "    passthrough=True  # 让元学习器直接访问原始特征\n",
        ")\n",
        "\n",
        "# 训练 Stacking 模型\n",
        "stacking_model4.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.使用voting方法将Gradient Boosting, XGBoost, Catboost 和Adaboost 组合为hybrid模型 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Accuracy for Voting Model: 0.953149195145666\n"
          ]
        }
      ],
      "source": [
        "# 加载模型\n",
        "best_gb_model = joblib.load('best_gradient_boosting_model.pkl')  # Gradient Boosting\n",
        "best_xgboost_model = joblib.load('best_xgboost_model.pkl')  # XGBoost\n",
        "best_catboost_model = joblib.load('best_catboost_model.pkl')  # CatBoost\n",
        "best_adaboost_model = joblib.load('best_adaboost_model.pkl')  # AdaBoost\n",
        "\n",
        "# 定义基学习器\n",
        "base_learners = [\n",
        "    ('gb', best_gb_model), \n",
        "    ('xgb', best_xgboost_model), \n",
        "    ('cat', best_catboost_model), \n",
        "    ('ab', best_adaboost_model)\n",
        "]\n",
        "\n",
        "# 使用 VotingClassifier 进行投票融合\n",
        "voting_model4 = VotingClassifier(\n",
        "    estimators=base_learners, \n",
        "    voting='soft'  # 软投票，可以改为 'hard' 使用硬投票\n",
        ")\n",
        "\n",
        "# 训练 Voting 模型\n",
        "voting_model4.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. 使用stack的方法将Gradient Boosting, XGBoost, Catboost, Adaboost 和Bagging 组合为hybrid模型 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Anconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Accuracy for Stacking Model: 0.9527170585905146\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 加载模型\n",
        "best_gb_model = joblib.load('best_gradient_boosting_model.pkl')  # Gradient Boosting\n",
        "best_xgboost_model = joblib.load('best_xgboost_model.pkl')  # XGBoost\n",
        "best_catboost_model = joblib.load('best_catboost_model.pkl')  # CatBoost\n",
        "best_adaboost_model = joblib.load('best_adaboost_model.pkl')  # AdaBoost\n",
        "best_bagging_model = joblib.load('best_bagging_model.pkl')\n",
        "\n",
        "# 定义基学习器\n",
        "base_learners = [\n",
        "    ('gb', best_gb_model),\n",
        "    ('xgb', best_xgboost_model),\n",
        "    ('cat', best_catboost_model),\n",
        "    ('ab', best_adaboost_model),\n",
        "    ('bag', best_bagging_model)\n",
        "]\n",
        "\n",
        "# 选择逻辑回归作为元学习器\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# 构建 StackingClassifier\n",
        "stacking_model5 = StackingClassifier(\n",
        "    estimators=base_learners, \n",
        "    final_estimator=meta_learner, \n",
        "    passthrough=True  # 让元学习器直接访问原始特征\n",
        ")\n",
        "\n",
        "# 训练 Stacking 模型\n",
        "stacking_model5.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. 使用voting的方法将Gradient Boosting, XGBoost, Catboost, Adaboost 和Bagging 组合为hybrid模型 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Accuracy for Voting Model: 0.9528611041088985\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 加载模型\n",
        "best_gb_model = joblib.load('best_gradient_boosting_model.pkl')  # Gradient Boosting\n",
        "best_xgboost_model = joblib.load('best_xgboost_model.pkl')  # XGBoost\n",
        "best_catboost_model = joblib.load('best_catboost_model.pkl')  # CatBoost\n",
        "best_adaboost_model = joblib.load('best_adaboost_model.pkl')  # AdaBoost\n",
        "best_bagging_model = joblib.load('best_bagging_model.pkl')  # Bagging\n",
        "\n",
        "# 定义基学习器\n",
        "base_learners = [\n",
        "    ('gb', best_gb_model),\n",
        "    ('xgb', best_xgboost_model),\n",
        "    ('cat', best_catboost_model),\n",
        "    ('ab', best_adaboost_model),\n",
        "    ('bag', best_bagging_model)\n",
        "]\n",
        "\n",
        "# 使用 VotingClassifier 进行投票融合\n",
        "voting_model5 = VotingClassifier(\n",
        "    estimators=base_learners, \n",
        "    voting='soft'  # 软投票，可以改为 'hard' 使用硬投票\n",
        ")\n",
        "\n",
        "# 训练 Voting 模型\n",
        "voting_model5.fit(X_train, Y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 保存所有混合模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Voting model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# 保存 VotingClassifier 模型\n",
        "joblib.dump(stacking_model3,'best_stacking_model3.pkl')\n",
        "joblib.dump(voting_model3, 'best_voting_model3.pkl')\n",
        "joblib.dump(stacking_model4,'best_stacking_model4.pkl')\n",
        "joblib.dump(voting_model4, 'best_voting_model4.pkl')\n",
        "joblib.dump(stacking_model5,'best_stacking_model5.pkl')\n",
        "joblib.dump(voting_model5, 'best_voting_model5.pkl')\n",
        "\n",
        "print(\"Voting model saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用已加载模型进行预测"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Accuracy for Loaded Voting Model3: 0.953149195145666\n",
            "Test Set Accuracy for Loaded Voting Model4: 0.953149195145666\n",
            "Test Set Accuracy for Loaded Voting Model5: 0.9528611041088985\n",
            "Test Set Accuracy for Loaded stacking Model3: 0.952392956174151\n",
            "Test Set Accuracy for Loaded stacking Model4: 0.9525730130721308\n",
            "Test Set Accuracy for Loaded stacking Model5: 0.9527170585905146\n"
          ]
        }
      ],
      "source": [
        "# 加载已保存的 VotingClassifier 模型\n",
        "loaded_voting_model3 = joblib.load('best_voting_model3.pkl')\n",
        "loaded_voting_model4 = joblib.load('best_voting_model4.pkl')\n",
        "loaded_voting_model5 = joblib.load('best_voting_model5.pkl')\n",
        "loaded_stacking_model3 = joblib.load('best_stacking_model3.pkl')\n",
        "loaded_stacking_model4 = joblib.load('best_stacking_model4.pkl')\n",
        "loaded_stacking_model5 = joblib.load('best_stacking_model5.pkl')\n",
        "# 使用加载的模型进行预测\n",
        "loaded_voting_predictions3 = loaded_voting_model3.predict(X_test)\n",
        "loaded_voting_predictions4 = loaded_voting_model4.predict(X_test)\n",
        "loaded_voting_predictions5 = loaded_voting_model5.predict(X_test)\n",
        "loaded_stacking_predictions3 = loaded_stacking_model3.predict(X_test)\n",
        "loaded_stacking_predictions4 = loaded_stacking_model4.predict(X_test)\n",
        "loaded_stacking_predictions5 = loaded_stacking_model5.predict(X_test)\n",
        "# 计算准确率\n",
        "loaded_voting_accuracy3 = accuracy_score(Y_test, loaded_voting_predictions3)\n",
        "loaded_voting_accuracy4 = accuracy_score(Y_test, loaded_voting_predictions4)\n",
        "loaded_voting_accuracy5 = accuracy_score(Y_test, loaded_voting_predictions5)\n",
        "loaded_stacking_accuracy3 = accuracy_score(Y_test, loaded_stacking_predictions3)\n",
        "loaded_stacking_accuracy4 = accuracy_score(Y_test, loaded_stacking_predictions4)\n",
        "loaded_stacking_accuracy5 = accuracy_score(Y_test, loaded_stacking_predictions5)\n",
        "\n",
        "# 打印出正确率\n",
        "print(f\"Test Set Accuracy for Loaded Voting Model3: {loaded_voting_accuracy3}\")\n",
        "print(f\"Test Set Accuracy for Loaded Voting Model4: {loaded_voting_accuracy4}\")\n",
        "print(f\"Test Set Accuracy for Loaded Voting Model5: {loaded_voting_accuracy5}\")\n",
        "print(f\"Test Set Accuracy for Loaded stacking Model3: {loaded_stacking_accuracy3}\")\n",
        "print(f\"Test Set Accuracy for Loaded stacking Model4: {loaded_stacking_accuracy4}\")\n",
        "print(f\"Test Set Accuracy for Loaded stacking Model5: {loaded_stacking_accuracy5}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 可视化模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy values for the models\n",
        "accuracies = [\n",
        "    ('Voting Model 3', loaded_voting_accuracy3),\n",
        "    ('Stacking Model 3', loaded_stacking_accuracy3),\n",
        "    ('Voting Model 4', loaded_voting_accuracy4),\n",
        "    ('Stacking Model 4', loaded_stacking_accuracy4),\n",
        "    ('Voting Model 5', loaded_voting_accuracy5),\n",
        "    ('Stacking Model 5', loaded_stacking_accuracy5)\n",
        "]\n",
        "\n",
        "# Extract model names and their corresponding accuracies\n",
        "models = [model[0] for model in accuracies]\n",
        "scores = [model[1] for model in accuracies]\n",
        "\n",
        "# Plotting the bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(models, scores, color=['blue', 'green', 'red', 'purple', 'orange', 'cyan'])\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Test Set Accuracy for Loaded Voting and Stacking Models')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylim([0.9522, 0.9535])  # Accuracy is between 0 and 1\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "22ol8piK2QIQ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier()),\n",
              "                               (&#x27;ab&#x27;, AdaBoostClassifier(n_estimators=100)),\n",
              "                               (&#x27;gb&#x27;, GradientBoostingClassifier())],\n",
              "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier()),\n",
              "                               (&#x27;ab&#x27;, AdaBoostClassifier(n_estimators=100)),\n",
              "                               (&#x27;gb&#x27;, GradientBoostingClassifier())],\n",
              "                   final_estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>ab</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(n_estimators=100)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "StackingClassifier(estimators=[('rf', RandomForestClassifier()),\n",
              "                               ('ab', AdaBoostClassifier(n_estimators=100)),\n",
              "                               ('gb', GradientBoostingClassifier())],\n",
              "                   final_estimator=LogisticRegression())"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create and train Voting Classifier models\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "    ('rf', base_models[0]),\n",
        "    ('ab', base_models_ab[0]),\n",
        "    ('gb', base_models_gb[0]),\n",
        "], voting='soft')\n",
        "voting_classifier.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "# Create and train Stacking Classifier models\n",
        "stacking_classifier = StackingClassifier(estimators=[\n",
        "    ('rf', base_models[0]),\n",
        "    ('ab', base_models_ab[0]),\n",
        "    ('gb', base_models_gb[0]),\n",
        "], final_estimator=LogisticRegression())\n",
        "stacking_classifier.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ieByea42QRA",
        "outputId": "20d76c58-2efd-4e04-ed71-027f9dff6aec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter number of Pregnancies: 0\n",
            "Enter Glucose level: 137\n",
            "Enter Blood Pressure: 40\n",
            "Enter Skin Thickness: 35\n",
            "Enter Insulin level: 168\n",
            "Enter BMI: 43.1\n",
            "Enter Diabetes Pedigree Function: 2.288\n",
            "Enter Age: 38\n",
            "The model predicts: Diabetes\n"
          ]
        }
      ],
      "source": [
        "# # Get input from the user\n",
        "# user_input = {\n",
        "#     'Pregnancies': float(input('Enter number of Pregnancies: ')),\n",
        "#     'Glucose': float(input('Enter Glucose level: ')),\n",
        "#     'BloodPressure': float(input('Enter Blood Pressure: ')),\n",
        "#     'SkinThickness': float(input('Enter Skin Thickness: ')),\n",
        "#     'Insulin': float(input('Enter Insulin level: ')),\n",
        "#     'BMI': float(input('Enter BMI: ')),\n",
        "#     'DiabetesPedigreeFunction': float(input('Enter Diabetes Pedigree Function: ')),\n",
        "#     'Age': float(input('Enter Age: '))\n",
        "# }\n",
        "\n",
        "# # Convert the user input into a DataFrame\n",
        "# user_df = pd.DataFrame([user_input])\n",
        "\n",
        "# # Make a prediction using the trained model\n",
        "# user_prediction = rf.predict(user_df)\n",
        "\n",
        "# # Interpret the prediction\n",
        "# if user_prediction[0] == 0:\n",
        "#     result = \"No diabetes\"\n",
        "# else:\n",
        "#     result = \"Diabetes\"\n",
        "\n",
        "# print(f\"The model predicts: {result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "hL1Ji4vs2QV8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPdFSVjhctXm2RPpjZ8gWTT",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
